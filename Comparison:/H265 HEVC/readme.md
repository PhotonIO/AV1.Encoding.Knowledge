# Discuss:
- https://www.reddit.com/r/unRAID/comments/1klcuj6/codec_showdown_av1_vs_h265_in_unmanic_realworld/

https://www.techpowerup.com/forums/threads/amd-h-265-destroys-av1-in-obs.326884/
quote:
- >"AMD's hardware encoders are very poor. It only really started getting better now with Navi 31. AV1 is the superior codec, but AMD's encoder might not be up to par."
- >"Ironically HW encoder quality is a area Intel has done well with. I'd actually use my iGPU on 14700K for video playback if desktop color depth was 10-bit. It can do video playback at 10-bit actual desktop bit depth is 8-bit. It's not worth the aggravation even though the video quality is better. I care more about standard usage across image details across all programs than I do just video playback. I don't feel like switch display outputs or going multi-display either it's a unneeded nuisance. The iGPU itself is actually moderately reasonable though. It's not great, but for integrate I'm still pleasantly surprised at how capable modern iGPU's have gotten. Intel's encoder quality is clean and crisp."
- >"AMDS AV1 hardware encoder is dogshit if you want av1 that works get a Arc or Nvidia card for transcode duty"

https://www.techpowerup.com/forums/threads/amd-h-265-destroys-av1-in-obs.326884/#post-5337212
- >Two screen shots  
>This is from a software encode using SVT-AV1 and using variance boost and tune 0 and preset 4
- >I agree something looks off. H265 is notoriously bad when it comes to dark scenes. AV1 is significantly better in that area. Overall AV1 has come a long way and I prefer it over H265 any day. Even though I have done thousands of H265 encodes using AVI-synth over the years. With a 9950x using avx-512 you can sometimes encode AV1 at > 100 fps using preset 5 and variance boost in 1080p.
